{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa893bb2",
   "metadata": {
    "papermill": {
     "duration": 0.003693,
     "end_time": "2025-08-09T18:52:53.902213",
     "exception": false,
     "start_time": "2025-08-09T18:52:53.898520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## This notebook is an end-to-end baseline for the MITSUI&CO. Commodity Prediction Challenge, designed to run entirely on CPU within the Kaggle environment and produce a valid first submission via the competitionâ€™s evaluation API.## \n",
    "\n",
    "\n",
    "### The approach is intentionally simple and serves as a starting point to understand the competitionâ€™s data flow and submission mechanics before adding complexity:\n",
    "\tâ€¢\tData: Uses only the lagged target values provided by the competition API (or offline lag files for local testing).\n",
    "\tâ€¢\tFeatures: For each target time series (target_0 â€¦ target_423), we construct lag features for the past 4 days.\n",
    "\tâ€¢\tModel: Fit an independent Ridge regression model per target, using the lag features to predict the current dayâ€™s return.\n",
    "\tâ€¢\tInference: In the online mode (submission), the model reads lag values via the evaluation API and predicts each target for each scoring day.\n",
    "\tâ€¢\tOffline fallback: When run interactively without the evaluation API (e.g., in local testing), the notebook uses test.csv + lagged label files to emulate the API so the code remains end-to-end.\n",
    "\n",
    "### This setup:\n",
    "\tâ€¢\tEnsures no forward-looking leakage (only past lags are used).\n",
    "\tâ€¢\tKeeps runtime fast (<2 mins on CPU).\n",
    "\tâ€¢\tProduces a valid benchmark score for the public leaderboard.\n",
    "\tâ€¢\tGives a clear framework to extend with richer features, alternative models, and ensembling in later iterations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6077e509",
   "metadata": {
    "papermill": {
     "duration": 0.002644,
     "end_time": "2025-08-09T18:52:53.908420",
     "exception": false,
     "start_time": "2025-08-09T18:52:53.905776",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "###  Imports & Warnings Setup\n",
    "\tâ€¢\tLoads standard Python libraries (numpy, pandas, sklearn for Ridge and scaling).\n",
    "\tâ€¢\tSuppresses irrelevant warnings for cleaner output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bda0b0e2",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-09T18:52:53.915341Z",
     "iopub.status.busy": "2025-08-09T18:52:53.914939Z",
     "iopub.status.idle": "2025-08-09T18:52:57.533749Z",
     "shell.execute_reply": "2025-08-09T18:52:57.532986Z"
    },
    "papermill": {
     "duration": 3.624296,
     "end_time": "2025-08-09T18:52:57.535470",
     "exception": false,
     "start_time": "2025-08-09T18:52:53.911174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# === MITSUI&CO. Commodity Prediction Challenge: CPU Baseline (v1) ===\n",
    "# End-to-end: trains tiny per-target Ridge models on lagged labels, then submits via the evaluation API.\n",
    "\n",
    "import os, sys, gc, math, warnings, importlib, pkgutil\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Lightweight, CPU-friendly model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173bac12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T18:52:57.542779Z",
     "iopub.status.busy": "2025-08-09T18:52:57.542322Z",
     "iopub.status.idle": "2025-08-09T18:52:57.550315Z",
     "shell.execute_reply": "2025-08-09T18:52:57.549422Z"
    },
    "papermill": {
     "duration": 0.013273,
     "end_time": "2025-08-09T18:52:57.551787",
     "exception": false,
     "start_time": "2025-08-09T18:52:57.538514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Utility: locate make_env()\n",
    "# -----------------------------\n",
    "def locate_make_env():\n",
    "    \"\"\"\n",
    "    Robustly locate the competition's evaluation API factory function.\n",
    "    Tries to discover the module under kaggle_evaluation.competition.* that has `make_env`.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import kaggle_evaluation.competition as kec\n",
    "    except Exception as e:\n",
    "        raise ImportError(\n",
    "            \"Could not import kaggle_evaluation. Are you running inside a Kaggle Notebook \"\n",
    "            \"AND have you joined the competition?\"\n",
    "        ) from e\n",
    "\n",
    "    # 1) Try to auto-discover a module with 'mitsui' or 'commodity' in name\n",
    "    for m in pkgutil.iter_modules(kec.__path__):\n",
    "        name = m.name.lower()\n",
    "        if (\"mitsui\" in name) or (\"commodity\" in name):\n",
    "            try:\n",
    "                mod = importlib.import_module(f\"kaggle_evaluation.competition.{m.name}\")\n",
    "                if hasattr(mod, \"make_env\"):\n",
    "                    return mod.make_env\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # 2) Try some likely names\n",
    "    candidates = [\n",
    "        \"mitsui_co_commodity_prediction\",\n",
    "        \"mitsui_commodity_prediction\",\n",
    "        \"commodity_prediction\",\n",
    "        \"mitsui2025\",\n",
    "    ]\n",
    "    for cand in candidates:\n",
    "        try:\n",
    "            mod = importlib.import_module(f\"kaggle_evaluation.competition.{cand}\")\n",
    "            if hasattr(mod, \"make_env\"):\n",
    "                return mod.make_env\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    # 3) Give an actionable error\n",
    "    raise ImportError(\n",
    "        \"Could not locate the competition's make_env(). \"\n",
    "        \"Open the competition page âžœ Evaluation tab, find the sample code line like:\\n\"\n",
    "        \"`from kaggle_evaluation.competition.<MODULE_NAME> import make_env`\\n\"\n",
    "        \"Then replace the locator above with that exact import.\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ad086",
   "metadata": {
    "papermill": {
     "duration": 0.00251,
     "end_time": "2025-08-09T18:52:57.557224",
     "exception": false,
     "start_time": "2025-08-09T18:52:57.554714",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load Training Labels & Identify Targets\n",
    "\tâ€¢\tReads train_labels.csv from the competition dataset.\n",
    "\tâ€¢\tExtracts all target_* columns that we need to predict.\n",
    "\tâ€¢\tEnsures the notebook will error early if the dataset isnâ€™t attached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81114a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T18:52:57.563862Z",
     "iopub.status.busy": "2025-08-09T18:52:57.563260Z",
     "iopub.status.idle": "2025-08-09T18:52:57.940722Z",
     "shell.execute_reply": "2025-08-09T18:52:57.939856Z"
    },
    "papermill": {
     "duration": 0.382686,
     "end_time": "2025-08-09T18:52:57.942483",
     "exception": false,
     "start_time": "2025-08-09T18:52:57.559797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using train_labels.csv at: /kaggle/input/mitsui-commodity-prediction-challenge/train_labels.csv\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# 2) Load training labels and build per-target datasets\n",
    "# ------------------------------------------------------\n",
    "# Expect these files from the competition dataset to be attached:\n",
    "# - train_labels.csv  (columns: date_id, target_0 ... target_423)\n",
    "# - (Optional here) train.csv, target_pairs.csv (not used in v1 baseline)\n",
    "labels_path = \"/kaggle/input/mitsui-commodity-prediction-challenge/train_labels.csv\"\n",
    "if not os.path.exists(labels_path):\n",
    "    # dataset title can change slightly; try alternate mount point\n",
    "    # You can also click \"Add Data\" and point to the right dataset.\n",
    "    for root, dirs, files in os.walk(\"/kaggle/input\"):\n",
    "        if \"train_labels.csv\" in files:\n",
    "            labels_path = os.path.join(root, \"train_labels.csv\")\n",
    "            break\n",
    "\n",
    "print(f\"Using train_labels.csv at: {labels_path}\")\n",
    "train_labels = pd.read_csv(labels_path)\n",
    "\n",
    "# Identify target columns\n",
    "target_cols = [c for c in train_labels.columns if c.startswith(\"target_\")]\n",
    "assert len(target_cols) > 0, \"No target_* columns found in train_labels.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e12e8ff",
   "metadata": {
    "papermill": {
     "duration": 0.002632,
     "end_time": "2025-08-09T18:52:57.948234",
     "exception": false,
     "start_time": "2025-08-09T18:52:57.945602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Build Lag Features & Train Ridge Models\n",
    "\tâ€¢\tDefines build_lagged_frame() to create lag features (lags 1 to 4) for each target.\n",
    "\tâ€¢\tIterates through all target columns:\n",
    "\tâ€¢\tCoerces values to numeric.\n",
    "\tâ€¢\tDrops rows with missing lag values.\n",
    "\tâ€¢\tFits a Ridge(alpha=0.5) model with standardized inputs.\n",
    "\tâ€¢\tStores the trained model and its scaler for use in prediction.\n",
    "\tâ€¢\tSkips targets with insufficient history (fallback to zero prediction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e658e18e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T18:52:57.954953Z",
     "iopub.status.busy": "2025-08-09T18:52:57.954605Z",
     "iopub.status.idle": "2025-08-09T18:53:00.353864Z",
     "shell.execute_reply": "2025-08-09T18:53:00.352944Z"
    },
    "papermill": {
     "duration": 2.404425,
     "end_time": "2025-08-09T18:53:00.355398",
     "exception": false,
     "start_time": "2025-08-09T18:52:57.950973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained models: 424/424 (fallback=0.0 for others)\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------\n",
    "# 3) Create lag features from train_labels (lags 1..4)\n",
    "#    We fit one Ridge per target: y_t ~ [y_{t-1}, y_{t-2}, y_{t-3}, y_{t-4}]\n",
    "# ------------------------------------------------------\n",
    "# --- replace build_lagged_frame and the training loop with the below ---\n",
    "\n",
    "def build_lagged_frame(df, value_col=\"y\", max_lag=4):\n",
    "    # df must have columns: ['date_id', value_col]\n",
    "    out = df[[\"date_id\", value_col]].copy()\n",
    "    out.rename(columns={value_col: \"y\"}, inplace=True)\n",
    "    for L in range(1, max_lag + 1):\n",
    "        out[f\"lag{L}\"] = out[\"y\"].shift(L)\n",
    "    # drop any rows with missing y or missing lags\n",
    "    out = out.dropna(subset=[\"y\"] + [f\"lag{i}\" for i in range(1, max_lag + 1)]).reset_index(drop=True)\n",
    "    return out\n",
    "\n",
    "models = {}\n",
    "scalers = {}\n",
    "\n",
    "for col in target_cols:\n",
    "    df_col = train_labels[[\"date_id\", col]].copy()\n",
    "    # ensure 1-D numeric series\n",
    "    df_col[col] = pd.to_numeric(df_col[col], errors=\"coerce\")\n",
    "    d = build_lagged_frame(df_col, value_col=col, max_lag=4)\n",
    "\n",
    "    if len(d) < 50:  # too little data => fallback later\n",
    "        continue\n",
    "\n",
    "    X = d[[f\"lag{i}\" for i in range(1, 5)]].values\n",
    "    y = d[\"y\"].values\n",
    "\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xs = scaler.fit_transform(X)\n",
    "\n",
    "    model = Ridge(alpha=0.5, random_state=42)\n",
    "    model.fit(Xs, y)\n",
    "\n",
    "    models[col] = model\n",
    "    scalers[col] = scaler\n",
    "\n",
    "print(f\"Trained models: {len(models)}/{len(target_cols)} (fallback=0.0 for others)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d132df70",
   "metadata": {
    "papermill": {
     "duration": 0.00282,
     "end_time": "2025-08-09T18:53:00.361420",
     "exception": false,
     "start_time": "2025-08-09T18:53:00.358600",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Online/Offline Prediction Pipeline\n",
    "\tâ€¢\tOnline Mode:\n",
    "\tâ€¢\tAttempts to import make_env from the competitionâ€™s kaggle_evaluation package.\n",
    "\tâ€¢\tRuns the iterative test loop (iter_test()) to receive lag values and output predictions via env.predict().\n",
    "\tâ€¢\tOffline Mode:\n",
    "\tâ€¢\tIf make_env is not available (typical in interactive runs without competition attachment), loads test.csv and lag files (test_labels_lag_1â€“4) to mimic the online flow.\n",
    "\tâ€¢\tProduces a local submission.csv so predictions can be inspected before submission.\n",
    "\tâ€¢\tBoth modes use the same per-target Ridge models trained earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d669ac2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T18:53:00.368451Z",
     "iopub.status.busy": "2025-08-09T18:53:00.368137Z",
     "iopub.status.idle": "2025-08-09T18:53:29.673167Z",
     "shell.execute_reply": "2025-08-09T18:53:29.672342Z"
    },
    "papermill": {
     "duration": 29.310932,
     "end_time": "2025-08-09T18:53:29.675084",
     "exception": false,
     "start_time": "2025-08-09T18:53:00.364152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Running local gateway (interactive sanity check)â€¦\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Stage 4 â€” Mitsui server API (no make_env)\n",
    "# Implements predict() using trained models,\n",
    "# then starts the inference server.\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import polars as pl\n",
    "except Exception:\n",
    "    pl = None\n",
    "\n",
    "# --- Safety nets for globals from earlier cells ---\n",
    "if 'target_cols' not in globals() or not target_cols:\n",
    "    # Default to 424 targets if we can't infer them\n",
    "    target_cols = [f\"target_{i}\" for i in range(424)]\n",
    "\n",
    "if 'models' not in globals():\n",
    "    models = {}\n",
    "if 'scalers' not in globals():\n",
    "    scalers = {}\n",
    "\n",
    "NUM_TARGET_COLUMNS = len(target_cols)\n",
    "\n",
    "# --- Replace the helpers + predict() with the robust versions below ---\n",
    "\n",
    "# --- Robust helpers that handle empty/NaN lag batches ---\n",
    "\n",
    "def _to_pd(df):\n",
    "    \"\"\"Accept polars or pandas, return pandas DataFrame (or None).\"\"\"\n",
    "    if df is None:\n",
    "        return None\n",
    "    if pl is not None and isinstance(df, pl.DataFrame):\n",
    "        return df.to_pandas()\n",
    "    return df\n",
    "\n",
    "def _ensure_one_row_targets(df: pd.DataFrame, target_cols: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a 1-row DataFrame with exactly target_* columns, NaNs filled with 0.\n",
    "    Handles None/empty/missing-cols cases gracefully.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        one = pd.DataFrame({c: [0.0] for c in target_cols})\n",
    "    else:\n",
    "        cols = [c for c in df.columns if str(c).startswith(\"target_\")]\n",
    "        if not cols:\n",
    "            one = pd.DataFrame({c: [0.0] for c in target_cols})\n",
    "        else:\n",
    "            one = df[cols].head(1).copy()\n",
    "            one = one.reindex(columns=target_cols, fill_value=0.0)\n",
    "    # fill any residual NaNs with zeros\n",
    "    return one.fillna(0.0)\n",
    "\n",
    "def _predict_row_from_lags(lag1, lag2, lag3, lag4):\n",
    "    \"\"\"Predict one row using up to 4 lag frames; safe against empties/NaNs.\"\"\"\n",
    "    L1 = _ensure_one_row_targets(_to_pd(lag1), target_cols)\n",
    "    L2 = _ensure_one_row_targets(_to_pd(lag2), target_cols)\n",
    "    L3 = _ensure_one_row_targets(_to_pd(lag3), target_cols)\n",
    "    L4 = _ensure_one_row_targets(_to_pd(lag4), target_cols)\n",
    "\n",
    "    preds = {}\n",
    "    for c in target_cols:\n",
    "        x = np.array([\n",
    "            float(L1.at[0, c]),\n",
    "            float(L2.at[0, c]),\n",
    "            float(L3.at[0, c]),\n",
    "            float(L4.at[0, c]),\n",
    "        ], dtype=\"float32\").reshape(1, -1)\n",
    "\n",
    "        # extra safety: nansâ†’0 (shouldn't be needed after fillna, but cheap)\n",
    "        if not np.isfinite(x).all():\n",
    "            x = np.nan_to_num(x, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        if c in models:\n",
    "            try:\n",
    "                xs = scalers[c].transform(x) if c in scalers and hasattr(scalers[c], \"transform\") else x\n",
    "                yhat = float(models[c].predict(xs)[0])\n",
    "            except Exception:\n",
    "                yhat = float(models[c].predict(x)[0])\n",
    "        else:\n",
    "            yhat = float(x[0, 0])  # naive carry-forward\n",
    "\n",
    "        preds[c] = yhat\n",
    "    return preds\n",
    "\n",
    "def predict(test, label_lags_1_batch, label_lags_2_batch, label_lags_3_batch, label_lags_4_batch):\n",
    "    # Build predictions defensively (handles None/empty/NaN)\n",
    "    preds = _predict_row_from_lags(label_lags_1_batch, label_lags_2_batch, label_lags_3_batch, label_lags_4_batch)\n",
    "    return pl.DataFrame([preds]) if pl is not None else pd.DataFrame([preds])\n",
    "\n",
    "# ---- Start the server exactly as the competition snippet expects ----\n",
    "import kaggle_evaluation.mitsui_inference_server as mitsui_srv\n",
    "\n",
    "inference_server = mitsui_srv.MitsuiInferenceServer(predict)\n",
    "\n",
    "# Kaggleâ€™s runner sets this env var in the scoring container.\n",
    "# Locally, we run a small gateway that feeds the public data to your server.\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    print(\"ðŸ”Œ Starting Mitsui inference server (scoring runtime)â€¦\")\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    print(\"ðŸ§ª Running local gateway (interactive sanity check)â€¦\")\n",
    "    # Adjust path if the dataset folder name differs in your /kaggle/input mount\n",
    "    inference_server.run_local_gateway(('/kaggle/input/mitsui-commodity-prediction-challenge/',))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d61ef1",
   "metadata": {
    "papermill": {
     "duration": 0.003974,
     "end_time": "2025-08-09T18:53:29.683661",
     "exception": false,
     "start_time": "2025-08-09T18:53:29.679687",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Next Steps â€“ Improving on the Baseline\n",
    "\n",
    "### This Ridge + lag-only baseline is meant to get a valid score and confirm the full pipeline works. The next versions can systematically improve predictive power while still respecting the no-leakage rules. Suggested directions:\n",
    "\t1.\tFeature Engineering from Price Data\n",
    "\tâ€¢\tLoad train.csv and target_pairs.csv to compute additional features beyond lagged labels:\n",
    "\tâ€¢\tRolling means/standard deviations of price differences.\n",
    "\tâ€¢\tRolling z-scores for each target pair.\n",
    "\tâ€¢\tRolling correlations between related assets.\n",
    "\tâ€¢\tVolatility estimates (e.g., EWMA).\n",
    "    \n",
    "\t2.\tCross-Validation for Hyperparameter Tuning\n",
    "\tâ€¢\tUse expanding-window or walk-forward validation to tune Ridge/Lasso/ElasticNet parameters per target.\n",
    "\tâ€¢\tEvaluate stability of parameters across different market periods.\n",
    "    \n",
    "\t3.\tAlternative Models\n",
    "\tâ€¢\tTry CPU-friendly gradient boosting models (LightGBM/XGBoost) on engineered features.\n",
    "\tâ€¢\tConsider simple ensembles blending Ridge with tree models to combine linear and non-linear effects.\n",
    "    \n",
    "\t4.\tTarget-Specific Modeling\n",
    "\tâ€¢\tGroup targets by asset type (LME, JPX, US, FX) and build specialized models per group.\n",
    "\tâ€¢\tUse group-level features such as macroeconomic indicators or commodity-specific signals.\n",
    "    \n",
    "\t5.\tStability Enhancements\n",
    "\tâ€¢\tBlend model predictions with naive carry-forward (last lag) to reduce over-reaction.\n",
    "\tâ€¢\tApply exponential decay on coefficients to adapt to recent regime changes.\n",
    "    \n",
    "\t6.\tRegular Monitoring & Leaderboard Tracking\n",
    "\tâ€¢\tSave and track each notebook version with a brief changelog of feature/model changes.\n",
    "\tâ€¢\tCompare public leaderboard jumps cautiously, remembering itâ€™s based on a mock test set in Phase 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e9d7fa",
   "metadata": {
    "papermill": {
     "duration": 0.002616,
     "end_time": "2025-08-09T18:53:29.689544",
     "exception": false,
     "start_time": "2025-08-09T18:53:29.686928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13044405,
     "sourceId": 94771,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.973898,
   "end_time": "2025-08-09T18:53:30.412732",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-09T18:52:48.438834",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
